# ðŸŽ­ AI Media Toolkit (Develop Branch)

This **AI-powered media processing suite** includes **Text-to-Speech, Lip-Sync, Avatar Swapping, and Audio Processing**, all within a single unified environment.

---

## ðŸŒŸ **Features**
- **Text-to-Speech (TTS)** â€“ Generate speech with voice cloning  
- **Lip-Sync (Wav2Lip)** â€“ AI-driven lip movement synced with audio  
- **Avatar Swapping** â€“ High-quality face swapping for avatars  
- **Audio Enhancement (UVR)** â€“ Remove noise, separate vocals/instruments  
- **One-Click Setup** â€“ Fully automated dependency installation  
- **GPU Acceleration** â€“ Supports **CUDA, MPS, or CPU**  

---

## ðŸ“‚ **Project Structure**
```
virtual_human_simulation/
â”œâ”€â”€ backend/                          # Backend Flask API and AI services
â”‚   â”œâ”€â”€ app.py                        # Main Flask application
â”‚   â”œâ”€â”€ common/                       # Shared utilities and models
â”‚   â”‚   â”œâ”€â”€ config.py                 # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ GPU_Check.py              # Auto-detect GPU/CPU (CUDA, MPS, etc.)
â”‚   â”‚   â”œâ”€â”€ auth.py                   # Authentication utilities
â”‚   â”‚   â”œâ”€â”€ NLP_model.py              # NLP Model for AI responses
â”‚   â”‚   â”œâ”€â”€ XTTS_MODEL/               # TTS Model files
â”‚   â”‚   â”œâ”€â”€ audio-separator-models/   # UVR model files
â”‚   â”‚   â””â”€â”€ checkpoints_A2H/          # LipSync & General Model Checkpoints
â”‚   â”œâ”€â”€ INTERVIEW/                    # Interview processing modules
â”‚   â”‚   â”œâ”€â”€ Resumeparser.py           # Resume parsing and question generation
â”‚   â”‚   â”œâ”€â”€ Interview_functions.py    # Interview management functions
â”‚   â”‚   â”œâ”€â”€ Interview_manager.py      # Interview orchestration
â”‚   â”‚   â””â”€â”€ INTERVIEWBOT_CLI.py       # Command-line interview interface
â”‚   â”œâ”€â”€ TTS/                          # Text-to-Speech (XTTS)
â”‚   â”‚   â”œâ”€â”€ Scripts/                  # TTS scripts and demos
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_demo.py           # TTS demonstration
â”‚   â”‚   â”‚   â”œâ”€â”€ TTS_LOAD_MODEL.py     # Model loading and inference
â”‚   â”‚   â”‚   â”œâ”€â”€ TTS_TRAIN_MODEL.py    # Model training
â”‚   â”‚   â”‚   â””â”€â”€ UVR_TTS.py            # Audio enhancement + TTS pipeline
â”‚   â”‚   â””â”€â”€ TTS/                      # TTS library files
â”‚   â”œâ”€â”€ UVR/                          # Audio Separation (Vocal/Instrument Split)
â”‚   â”‚   â”œâ”€â”€ uvr/                      # UVR execution scripts and models
â”‚   â”‚   â””â”€â”€ audio_enhancer.py         # Main UVR processing script
â”‚   â”œâ”€â”€ Audio2Head/                   # Audio-to-Head movement synthesis
â”‚   â”‚   â”œâ”€â”€ modules/                  # Audio2Head modules
â”‚   â”‚   â””â”€â”€ sync_batchnorm/           # Synchronized batch normalization
â”‚   â”œâ”€â”€ Flask_UI/                     # Flask-based Web UI
â”‚   â”‚   â”œâ”€â”€ static/                   # Static files (CSS, JS, images)
â”‚   â”‚   â”œâ”€â”€ models.py                 # Database models
â”‚   â”‚   â”œâ”€â”€ import_secrets.py         # Secret management
â”‚   â”‚   â””â”€â”€ README.md                 # Flask UI documentation
â”‚   â”œâ”€â”€ model_download.py             # Model download utilities
â”‚   â”œâ”€â”€ start.sh                      # Backend startup script
â”‚   â””â”€â”€ README.md                     # Backend documentation
â”œâ”€â”€ frontend/                         # React-based web application
â”‚   â”œâ”€â”€ src/                          # React source code
â”‚   â”‚   â”œâ”€â”€ components/               # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ AuthDebug.jsx         # Authentication debugging
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx            # Navigation component
â”‚   â”‚   â”‚   â”œâ”€â”€ ThemeToggle.jsx       # Theme switching
â”‚   â”‚   â”‚   â”œâ”€â”€ interview/            # Interview-related components
â”‚   â”‚   â”‚   â”œâ”€â”€ landing/              # Landing page components
â”‚   â”‚   â”‚   â”œâ”€â”€ upload/               # File upload components
â”‚   â”‚   â”‚   â””â”€â”€ ui/                   # UI components
â”‚   â”‚   â”œâ”€â”€ pages/                    # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ InterviewPage.jsx     # Interview interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Landing.jsx           # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.jsx             # Login page
â”‚   â”‚   â”‚   â”œâ”€â”€ ProfilePage.jsx       # User profile
â”‚   â”‚   â”‚   â”œâ”€â”€ QuestionPage.jsx      # Question management
â”‚   â”‚   â”‚   â”œâ”€â”€ SignUp.jsx            # Registration page
â”‚   â”‚   â”‚   â”œâ”€â”€ TestPage.jsx          # Testing page
â”‚   â”‚   â”‚   â””â”€â”€ UploadPage.jsx        # File upload page
â”‚   â”‚   â”œâ”€â”€ contexts/                 # React contexts
â”‚   â”‚   â”‚   â””â”€â”€ AuthContext.jsx       # Authentication context
â”‚   â”‚   â”œâ”€â”€ hooks/                    # Custom React hooks
â”‚   â”‚   â”‚   â””â”€â”€ useTheme.js           # Theme management hook
â”‚   â”‚   â”œâ”€â”€ api.js                    # API integration
â”‚   â”‚   â”œâ”€â”€ supabaseClient.js         # Supabase client configuration
â”‚   â”‚   â”œâ”€â”€ App.jsx                   # Main App component
â”‚   â”‚   â”œâ”€â”€ main.jsx                  # Application entry point
â”‚   â”‚   â””â”€â”€ index.css                 # Global styles
â”‚   â”œâ”€â”€ public/                       # Public assets
â”‚   â”‚   â”œâ”€â”€ assets/                   # Static assets
â”‚   â”‚   â”‚   â”œâ”€â”€ interview/            # Interview-related assets
â”‚   â”‚   â”‚   â””â”€â”€ landing/              # Landing page assets
â”‚   â”‚   â””â”€â”€ vite.svg                  # Vite logo
â”‚   â”œâ”€â”€ package.json                  # Node.js dependencies
â”‚   â”œâ”€â”€ vite.config.js                # Vite configuration
â”‚   â”œâ”€â”€ tailwindcss.config.js         # Tailwind CSS configuration
â”‚   â”œâ”€â”€ eslint.config.js              # ESLint configuration
â”‚   â””â”€â”€ README.md                     # Frontend documentation
â”œâ”€â”€ supabase/                         # Supabase backend services
â”‚   â”œâ”€â”€ config.toml                   # Supabase configuration
â”‚   â”œâ”€â”€ migrations/                   # Database migrations
â”‚   â””â”€â”€ functions/                    # Edge functions
â”‚       â”œâ”€â”€ create-user/              # User creation function
â”‚       â”œâ”€â”€ dodo-webhook/             # Webhook handler
â”‚       â”œâ”€â”€ interview-feedback/       # Interview feedback processing
â”‚       â”œâ”€â”€ interviews/               # Interview management
â”‚       â”œâ”€â”€ job-descriptions/         # Job description handling
â”‚       â”œâ”€â”€ payments/                 # Payment processing
â”‚       â”œâ”€â”€ questions/                # Question management
â”‚       â”œâ”€â”€ resume-test/              # Resume testing
â”‚       â”œâ”€â”€ resumes/                  # Resume processing
â”‚       â”œâ”€â”€ transcripts/              # Transcript management
â”‚       â””â”€â”€ upload-file/              # File upload handling
â”œâ”€â”€ supabase_Scripts/                 # Supabase utility scripts
â”‚   â”œâ”€â”€ all_db_edge_operations.py     # Database operations
â”‚   â”œâ”€â”€ db_operations.py              # Database utilities
â”‚   â”œâ”€â”€ main.py                       # Main script runner
â”‚   â”œâ”€â”€ supabase_storage.py           # Storage utilities
â”‚   â””â”€â”€ Test_Resumes/                 # Test resume files
â”œâ”€â”€ install_dependencies.bat          # Windows dependency installer
â”œâ”€â”€ install_dependencies.sh           # Linux/macOS dependency installer
â”œâ”€â”€ start_dev.bat                     # Windows development server starter
â”œâ”€â”€ start_dev.sh                      # Linux/macOS development server starter
â”œâ”€â”€ INSTALLATION_GUIDE.md             # Detailed installation guide
â””â”€â”€ README.md                         # This file
```

## **Installation & Setup**

### **Prerequisites**

Ensure you have **Python 3.10** installed on your system.

### **1. Clone the Repository**
```bash
git clone https://github.com/moback-ai/virtual_human_simulation.git
cd virtual_human_simulation
```

### **2. Create Virtual Environment**

#### **For Windows:**
```bash
py -3.10 -m venv test1
```

#### **For Linux/macOS:**
```bash
python3.10 -m venv test1
```

### **3. Activate Virtual Environment**

#### **For Windows:**
```bash
.\test1\Scripts\activate
```

#### **For Linux/macOS:**
```bash
source test1/bin/activate
```

### **4. Install Dependencies**

#### **For Windows:**
```bash
.\install_dependencies.bat
```

#### **For Linux/macOS:**
```bash
chmod +x install_dependencies.sh
./install_dependencies.sh
```

### **5. Install Ollama**
Ollama is required for AI model inference. Follow these steps:

#### Step 1: Visit the Official Ollama Website
- Open your browser and navigate to: [https://ollama.ai](https://ollama.ai)

#### Step 2: Download and Install
- Select your operating system (Windows, macOS, or Linux).
- Follow the installation instructions provided on the website.

#### Step 3: Verify Installation
- Open a terminal and run the following command:
```bash
ollama --version
```
- If the command returns a version number, Ollama has been installed successfully.

### **6. Install FFmpeg**
The script uses `pydub`, which requires **FFmpeg**. Install it by following these steps:

#### **For Windows:**

**Download FFmpeg**  
- Open a web browser.  
- Navigate to **[Windows build from gyan.dev](https://www.gyan.dev/ffmpeg/builds/)**.  
- Under **"Git Master Builds,"** locate and download:  
    ```text
    ffmpeg-git-full.7z
    ```

**Extract and Move FFmpeg**  
- Once downloaded, extract the `.7z` file using **WinRAR** or **7-Zip**.  
- Move the extracted folder to:  
    ```text
    C:\Program Files\
    ```
- Open the extracted folder, navigate to the **bin** directory, and copy the full path. Example:  
    ```text
    C:\Program Files\ffmpeg-7.1-full_build\bin
    ```

**Set Up Environment Variables**  
- In the **Windows Search Bar**, type:  
    ```text
    Edit the system environment variables
    ```  
- Click on **Environment Variables** at the bottom of the window.  
- Under **User Variables**, locate and select **Path**, then click **Edit**.  
- In the **Edit Environment Variable** window, click **New**, paste the copied FFmpeg **bin** path, and click **OK**.  
- Click **OK** on all open windows to save the changes.  

#### **For Linux/macOS:**
```bash
sudo apt install ffmpeg   # Ubuntu/Debian
brew install ffmpeg       # macOS (Homebrew)
```

**Verify FFmpeg Installation:**
```bash
ffmpeg -version
```

### **7. Start Development Server**

#### **For Windows:**
```bash
start_dev.bat
```

#### **For Linux/macOS:**
```bash
chmod +x start_dev.sh
./start_dev.sh
```

---

## **Running the Application**

After completing the installation and setup steps above, the development server will automatically start and you can access the application through your web browser.

The application includes:
- **Frontend**: React-based web interface
- **Backend**: Flask API server
- **Database**: Supabase integration
- **AI Services**: Ollama-powered interview and resume processing

---

## **Project Structure**
All the necessary model files, your `backend/common/` folder should look like this:

```
backend/common/
â”œâ”€â”€ audio-separator-models/                                      # UVR model files
â”‚ â”œâ”€â”€ download_checks.json
â”‚ â”œâ”€â”€ Kim_Vocal_2.onnx
â”‚ â”œâ”€â”€ mdx_model_data.json
â”‚ â”œâ”€â”€ model_mel_band_roformer_ep_3005_sdr_11.4360.ckpt
â”‚ â”œâ”€â”€ model_mel_band_roformer_ep_3005_sdr_11.4360.yaml
â”‚ â”œâ”€â”€ vr_model_data.json
â”œâ”€â”€ XTTS_MODEL/                                                  # XTTS model files
â”‚ â”œâ”€â”€ config.json
â”‚ â”œâ”€â”€ dvae.pth
â”‚ â”œâ”€â”€ mel_stats.pth
â”‚ â”œâ”€â”€ model.pth
â”‚ â”œâ”€â”€ vocab.json
â”œâ”€â”€ checkpoints_A2H/                                                 # LipSync & General Model Checkpoints
â”‚ â”œâ”€â”€ audio2head.pth.tar
â”œâ”€â”€ config.py # Centralized configuration file
â”œâ”€â”€ GPU_Check.py # Auto-detects GPU/CPU (CUDA, MPS, etc.)
```

---

## **Troubleshooting**

### **Common Issues:**

1. **Virtual Environment Not Activated**: Make sure you see `(test1)` at the beginning of your command prompt/terminal
2. **Python Version**: Ensure you're using Python 3.10
3. **FFmpeg Not Found**: Verify FFmpeg is properly installed and added to your system PATH
4. **Ollama Not Running**: Start Ollama service before running the application

### **Getting Help:**
- Check the logs in the terminal for specific error messages
- Ensure all dependencies are properly installed
- Verify that all required model files are in the correct directories
